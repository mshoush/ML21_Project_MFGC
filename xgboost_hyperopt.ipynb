{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b155635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas for data wrangling\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import numpy for Scientific computations\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# import machine learning libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7770c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels:\n",
    "# 0 = failing\n",
    "# 1 = stable\n",
    "# 2 = growing\n",
    "\n",
    "def get_label_numeric(data):\n",
    "    y = get_label(data)  # one row per case\n",
    "    return [2 if label == 'growing' else 1 if label == 'stable' else 0 for label in y]\n",
    "\n",
    "def get_label(data):\n",
    "    return data[\"label\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52d0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):    \n",
    "    df_all_v1 = pd.read_csv(file)\n",
    "    try:\n",
    "        df_all_v1 = df_all_v1.drop(['Unnamed: 0', 'Registration_date', 'EMTAK_by_number', 'Client_ID_by_Eesti_Pank'],axis=1)\n",
    "    except: \n",
    "        df_all_v1 = df_all_v1.drop(['Registration_date', 'EMTAK_by_number', 'Client_ID_by_Eesti_Pank'],axis=1)\n",
    "        \n",
    "    df_all_v1 = df_all_v1.sort_values(by=['year_quarter'])\n",
    "    \n",
    "    return df_all_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1994f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['./data/full_v1.csv',\n",
    "        './data/full_v2.csv',\n",
    "        './data/before_v1.csv',\n",
    "        './data/before_v2.csv',\n",
    "        './data/during_v1.csv',\n",
    "        './data/during_v2.csv']\n",
    "\n",
    "dfs = {}\n",
    "for file in files:\n",
    "    name = file.split('/')[2]\n",
    "    df = read_data(file)\n",
    "    dfs[name] = df\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bc85c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((164194, 15), (383122, 15))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dfs['during_v1.csv'].reset_index(drop=True)\n",
    "data = data.drop([ 'Registration_number', 'year_quarter'], axis=1)\n",
    "data['label'] = [2 if label == 'growing' else 1 if label == 'stable' else 0 for label in data['label']]\n",
    "\n",
    "train_df, test_df = np.split(data, [int(0.3 *len(df))]) \n",
    "train_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272e61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb68b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set is of length:  131355\n",
      "The validation set is of length:  32839\n",
      "Training with params:                                 \n",
      "[12:01:33] WARNING: ../src/learner.cc:541:            \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\teval-merror:0.23113\ttrain-merror:0.22256          \n",
      "\n",
      "[1]\teval-merror:0.23600\ttrain-merror:0.22517          \n",
      "\n",
      "[2]\teval-merror:0.22665\ttrain-merror:0.21585          \n",
      "\n",
      "[3]\teval-merror:0.22623\ttrain-merror:0.21551          \n",
      "\n",
      "[4]\teval-merror:0.22291\ttrain-merror:0.21224          \n",
      "\n",
      "[5]\teval-merror:0.22230\ttrain-merror:0.20961          \n",
      "\n",
      "[6]\teval-merror:0.22132\ttrain-merror:0.20810          \n",
      "\n",
      "[7]\teval-merror:0.21959\ttrain-merror:0.20583          \n",
      "\n",
      "[8]\teval-merror:0.21916\ttrain-merror:0.20400          \n",
      "\n",
      "[9]\teval-merror:0.21873\ttrain-merror:0.20282          \n",
      "\n",
      "[10]\teval-merror:0.21822\ttrain-merror:0.20096         \n",
      "\n",
      "[11]\teval-merror:0.21815\ttrain-merror:0.20019         \n",
      "\n",
      "[12]\teval-merror:0.21724\ttrain-merror:0.19884         \n",
      "\n",
      "[13]\teval-merror:0.21618\ttrain-merror:0.19784         \n",
      "\n",
      "[14]\teval-merror:0.21560\ttrain-merror:0.19632         \n",
      "\n",
      "[15]\teval-merror:0.21572\ttrain-merror:0.19526         \n",
      "\n",
      "[16]\teval-merror:0.21477\ttrain-merror:0.19386         \n",
      "\n",
      "[17]\teval-merror:0.21453\ttrain-merror:0.19273         \n",
      "\n",
      "[18]\teval-merror:0.21465\ttrain-merror:0.19137         \n",
      "\n",
      "[19]\teval-merror:0.21493\ttrain-merror:0.18973         \n",
      "\n",
      "[20]\teval-merror:0.21490\ttrain-merror:0.18873         \n",
      "\n",
      "[21]\teval-merror:0.21438\ttrain-merror:0.18754         \n",
      "\n",
      "[22]\teval-merror:0.21383\ttrain-merror:0.18638         \n",
      "\n",
      "[23]\teval-merror:0.21353\ttrain-merror:0.18509         \n",
      "\n",
      "[24]\teval-merror:0.21283\ttrain-merror:0.18406         \n",
      "\n",
      "[25]\teval-merror:0.21298\ttrain-merror:0.18276         \n",
      "\n",
      "[26]\teval-merror:0.21286\ttrain-merror:0.18199         \n",
      "\n",
      "[27]\teval-merror:0.21264\ttrain-merror:0.18158         \n",
      "\n",
      "[28]\teval-merror:0.21240\ttrain-merror:0.18080         \n",
      "\n",
      "[29]\teval-merror:0.21219\ttrain-merror:0.18046         \n",
      "\n",
      "[30]\teval-merror:0.21210\ttrain-merror:0.17913         \n",
      "\n",
      "[31]\teval-merror:0.21213\ttrain-merror:0.17876         \n",
      "\n",
      "[32]\teval-merror:0.21188\ttrain-merror:0.17794         \n",
      "\n",
      "[33]\teval-merror:0.21170\ttrain-merror:0.17734         \n",
      "\n",
      "[34]\teval-merror:0.21170\ttrain-merror:0.17640         \n",
      "\n",
      "[35]\teval-merror:0.21109\ttrain-merror:0.17589         \n",
      "\n",
      "[36]\teval-merror:0.21161\ttrain-merror:0.17541         \n",
      "\n",
      "[37]\teval-merror:0.21121\ttrain-merror:0.17444         \n",
      "\n",
      "[38]\teval-merror:0.21146\ttrain-merror:0.17365         \n",
      "\n",
      "[39]\teval-merror:0.21152\ttrain-merror:0.17276         \n",
      "\n",
      "[40]\teval-merror:0.21149\ttrain-merror:0.17230         \n",
      "\n",
      "[41]\teval-merror:0.21097\ttrain-merror:0.17169         \n",
      "\n",
      "[42]\teval-merror:0.21075\ttrain-merror:0.17070         \n",
      "\n",
      "[43]\teval-merror:0.21036\ttrain-merror:0.17042         \n",
      "\n",
      "[44]\teval-merror:0.21027\ttrain-merror:0.16951         \n",
      "\n",
      "[45]\teval-merror:0.21039\ttrain-merror:0.16902         \n",
      "\n",
      "[46]\teval-merror:0.21012\ttrain-merror:0.16752         \n",
      "\n",
      "[47]\teval-merror:0.20984\ttrain-merror:0.16702         \n",
      "\n",
      "[48]\teval-merror:0.20981\ttrain-merror:0.16629         \n",
      "\n",
      "[49]\teval-merror:0.20993\ttrain-merror:0.16548         \n",
      "\n",
      "[50]\teval-merror:0.20951\ttrain-merror:0.16466         \n",
      "\n",
      "[51]\teval-merror:0.20932\ttrain-merror:0.16404         \n",
      "\n",
      "  0%|          | 0/50 [00:17<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "# Run an XGBoost model with hyperparmaters that are optimized using hyperopt\n",
    "# The output of the script are the best hyperparmaters\n",
    "# The optimization part using hyperopt is partly inspired from the following script: \n",
    "# https://github.com/bamine/Kaggle-stuff/blob/master/otto/hyperopt_xgboost.py\n",
    "\n",
    "\n",
    "# Data wrangling\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Scientific \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Machine learning\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hyperparameters tuning\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# Some constants\n",
    "\n",
    "SEED = 314159265\n",
    "VALID_SIZE = 0.2\n",
    "TARGET = 'label'\n",
    "\n",
    "# Scoring and optimization functions\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    #print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(train_features, label=y_train)\n",
    "    dvalid = xgb.DMatrix(valid_features, label=y_valid)\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    params['num_class'] = len(np.unique(y_train))\n",
    "    gbm_model = xgb.train(params, dtrain, num_round,\n",
    "                          evals=watchlist,\n",
    "                          verbose_eval=True)\n",
    "    predictions = gbm_model.predict(dvalid,\n",
    "                                    ntree_limit=gbm_model.best_iteration + 1)\n",
    "    #predictions = np.argmax(predictions, axis =1)\n",
    "\n",
    "    print((predictions))\n",
    "    print((y_valid))\n",
    "    score = roc_auc_score(y_valid, predictions, multi_class='ovr', average=\"macro\")\n",
    "    # TODO: Add the importance for the selected features\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def optimize(\n",
    "             #trials, \n",
    "             random_state=SEED):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of \n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "    # To learn more about XGBoost parameters, head to this page: \n",
    "    # https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 1000, 1),\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        # A problem with max_depth casted to float instead of int with\n",
    "        # the hp.quniform method.\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        'eval_metric': 'merror', # Multiclass classification error rate. It is calculated as \n",
    "        'objective': 'multi:softprob',\n",
    "        # Increase this number if you have more cores. Otherwise, remove it and it will default \n",
    "        # to the maxium number. \n",
    "        'nthread': 4,\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'exact',\n",
    "        'silent': 1,\n",
    "        'seed': random_state\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                # trials=trials, \n",
    "                max_evals=50)\n",
    "    return best\n",
    "\n",
    "#-------------------------------------------------#\n",
    "\n",
    "\n",
    "# Load processed data\n",
    "\n",
    "train_df = train_df\n",
    "test_df = test_df\n",
    "\n",
    "\n",
    "#-------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# Extract the train and valid (used for validation) dataframes from the train_df\n",
    "\n",
    "train, valid = train_test_split(train_df, test_size=VALID_SIZE,\n",
    "                                random_state=SEED, stratify=train_df['label'])\n",
    "\n",
    "y_train = train[TARGET]\n",
    "y_valid = valid[TARGET]\n",
    "\n",
    "\n",
    "train_features = train.drop([ 'label'], axis=1)\n",
    "valid_features = valid.drop([ 'label'], axis=1)\n",
    "\n",
    "# print(f\"train.shape: {train_features.shape} \\n,\\\n",
    "# valid.shape: {valid_features.shape} \\n,\\\n",
    "# len(y_train): {len(y_train)} \\n \\\n",
    "# len(y_valid): {len(y_valid)} \")\n",
    "\n",
    "print('The training set is of length: ', len(train.index))\n",
    "print('The validation set is of length: ', len(valid.index))\n",
    "\n",
    "#-------------------------------------------------#\n",
    "\n",
    "# Run the optimization\n",
    "\n",
    "# Trials object where the history of search will be stored\n",
    "# For the time being, there is a bug with the following version of hyperopt.\n",
    "# You can read the error messag on the log file.\n",
    "# For the curious, you can read more about it here: https://github.com/hyperopt/hyperopt/issues/234\n",
    "# => So I am commenting it.\n",
    "# trials = Trials()\n",
    "\n",
    "best_hyperparams = optimize(\n",
    "                            #trials\n",
    "                            )\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b8a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "    \n",
    "for data_name in dfs.keys():\n",
    "    print(data_name)\n",
    "    data = dfs[data_name].reset_index(drop=True)\n",
    "    data = data.drop([ 'Registration_number', 'year_quarter'], axis=1)\n",
    "    data['label'] = [2 if label == 'growing' else 1 if label == 'stable' else 0 for label in data['label']]\n",
    "\n",
    "    train_df, test_df = np.split(data, [int(0.3 *len(df))]) \n",
    "    print(train_df.shape, test_df.shape)\n",
    "    #break\n",
    "\n",
    "    train_df = train_df\n",
    "    test_df = test_df\n",
    "\n",
    "    y_train = np.array(train_df['label'])\n",
    "    X_train = train_df.drop(['label'], axis=1)\n",
    "\n",
    "\n",
    "    y_test = np.array(test_df['label'])\n",
    "    X_test = test_df.drop(['label'], axis=1)\n",
    "\n",
    "    clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
    "             gamma=best_hyperparams['gamma'], max_delta_step=0.0, min_child_weight=best_hyperparams['min_child_weight'],\n",
    "             missing=None, n_jobs=-1, objective='multi:softprob', random_state=42, reg_alpha=0.0,\n",
    "             reg_lambda=1.0, scale_pos_weight=1.0, tree_method='auto',\n",
    "             colsample_bytree =best_hyperparams['colsample_bytree'], \n",
    "             eta = best_hyperparams['eta'], \n",
    "             max_depth = best_hyperparams['max_depth'], \n",
    "             subsample = best_hyperparams['subsample'], \n",
    "             n_estimators = int(best_hyperparams['n_estimators']),\n",
    "                              nthread= 4, use_label_encoder=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    #predicting the data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob_pred = clf.predict_proba(X_test)\n",
    "\n",
    "    #roc auc score\n",
    "    print(roc_auc_score(y_test, y_prob_pred, multi_class='ovo', average='weighted'))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    target_names = ['Failing: 0', 'Stabel: 1', 'Growing: 2']\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "    clf_report = classification_report(y_test,\n",
    "                                       y_pred,\n",
    "                                       labels=np.arange(3),\n",
    "                                       target_names=target_names,\n",
    "                                       output_dict=True)\n",
    "\n",
    "\n",
    "    # .iloc[:-1, :] to exclude support\n",
    "    \n",
    "    sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.imshow(pd.DataFrame(clf_report).iloc[:-1, :].T, cmap='hot', interpolation='nearest',aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "    # roc curve for classes\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    thresh ={}\n",
    "\n",
    "    n_class = 3\n",
    "\n",
    "    for i in range(n_class):    \n",
    "        fpr[i], tpr[i], thresh[i] = roc_curve(y_test, y_prob_pred[:,i], pos_label=i)\n",
    "\n",
    "    # plotting    \n",
    "    plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Failing vs Rest')\n",
    "    plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Stabel vs Rest')\n",
    "    plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Growing vs Rest')\n",
    "    #plt.plot(fpr[3], tpr[3], linestyle='--',color='yellow', label='Class 3 vs Rest')\n",
    "    plt.title('Multiclass ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive rate')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Multiclass ROC',dpi=300); \n",
    "    print(\"=================================================\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import classification_report\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# target_names = ['Failing: 0', 'Stabel: 1', 'Growing: 2']\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "# clf_report = classification_report(y_test,\n",
    "#                                    y_pred,\n",
    "#                                    labels=np.arange(3),\n",
    "#                                    target_names=target_names,\n",
    "#                                    output_dict=True)\n",
    "\n",
    "\n",
    "# # .iloc[:-1, :] to exclude support\n",
    "# sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c55db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.imshow(pd.DataFrame(clf_report).iloc[:-1, :].T, cmap='hot', interpolation='nearest',aspect='auto')\n",
    "# plt.show()\n",
    "\n",
    "# # roc curve for classes\n",
    "# fpr = {}\n",
    "# tpr = {}\n",
    "# thresh ={}\n",
    "\n",
    "# n_class = 3\n",
    "\n",
    "# for i in range(n_class):    \n",
    "#     fpr[i], tpr[i], thresh[i] = roc_curve(y_test, y_prob_pred[:,i], pos_label=i)\n",
    "    \n",
    "# # plotting    \n",
    "# plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Failing vs Rest')\n",
    "# plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Stabel vs Rest')\n",
    "# plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Growing vs Rest')\n",
    "# #plt.plot(fpr[3], tpr[3], linestyle='--',color='yellow', label='Class 3 vs Rest')\n",
    "# plt.title('Multiclass ROC curve')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive rate')\n",
    "# plt.legend(loc='best')\n",
    "# plt.grid(True)\n",
    "# plt.savefig('Multiclass ROC',dpi=300); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390599c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
